{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from groq import Groq\n",
    "from time import sleep\n",
    "import re\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dprint(s, debug):\n",
    "    if debug:\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "YOUR_GROQ_API_KEY = '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'  # Get from https://console.groq.com/keys\n",
    "groq_client = Groq(api_key=YOUR_GROQ_API_KEY)\n",
    "\n",
    "def call_groq_api(prompt, student_configs, pre_processing, post_processing, model='llama3-70b-8192', debug=False):\n",
    "    prompt = pre_processing(prompt)\n",
    "    \n",
    "    groq_params = {\n",
    "        'messages': [{'role': 'user', 'content': prompt}],\n",
    "        'model': model,\n",
    "        'max_tokens': student_configs.get('max_tokens', 512),\n",
    "        'temperature': student_configs.get('temperature', 0.7),\n",
    "        'top_p': student_configs.get('top_p', 0.7),\n",
    "        'stop': student_configs.get('stop', None),\n",
    "    }\n",
    "    \n",
    "    output = groq_client.chat.completions.create(**groq_params)\n",
    "    \n",
    "    dprint('*****prompt*****', debug)\n",
    "    dprint(prompt, debug)\n",
    "    dprint('*****result*****', debug)\n",
    "    res = output.choices[0].message.content\n",
    "    dprint(res, debug)\n",
    "    dprint('*****output*****', debug)\n",
    "    labels_only = post_processing(res)\n",
    "    dprint('POST PROCESSED', debug)\n",
    "    dprint(labels_only, debug)\n",
    "    dprint('=========', debug)\n",
    "    return labels_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_names = [\n",
    "#     'togethercomputer/llama-2-7b', #LLaMa-2-7B\n",
    "#     'togethercomputer/llama-2-13b', #LLaMa-2-13B\n",
    "#     'togethercomputer/llama-2-70b', #LLaMa-2-70B\n",
    "#     'togethercomputer/llama-2-70b-chat', #LLaMa-2-70B-Chat\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most likely current Groq model names:\n",
    "model_names = [\n",
    "    'llama-3.1-8b-instant',     \n",
    "    \"llama-3.3-70b-versatile\",              \n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_df(topn = 10):\n",
    "    train_df = pd.read_excel('train_split.xlsx')\n",
    "    return train_df[:topn]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_set():\n",
    "    test_df = pd.read_excel('test_split.xlsx')\n",
    "    return test_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_df(topn = 5):\n",
    "    eval_df = pd.read_excel('train_split.xlsx')\n",
    "    return eval_df.sample(topn)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_range(df, prompt_configs, prompt_prefix, examples, prompt_suffix,\n",
    "               pre_processing=lambda x:x, post_processing=lambda y:y,\n",
    "               model='llama-3.1-8b-instant', debug=False):\n",
    "    text_ids = []\n",
    "    answers = []\n",
    "    model_responses = []\n",
    "    corrected_model_responses = []\n",
    "    text_list = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows()):\n",
    "        text_ids.append(idx)  # Use index as ID if no ID column\n",
    "        fixed_prompt = row['text'] + \"\\n\"\n",
    "        text_list.append(row['text'])\n",
    "        fixed_prompt = pre_processing(fixed_prompt)\n",
    "        prompt = prompt_prefix + examples + fixed_prompt + prompt_suffix\n",
    "        answer = row['label']\n",
    "        answers.append(answer)\n",
    "        model_response = call_groq_api(prompt, prompt_configs, pre_processing, lambda y:y, model=model, debug=debug) \n",
    "        corrected_model_response = post_processing(model_response)\n",
    "        corrected_model_responses.append(corrected_model_response)\n",
    "        model_responses.append(model_response)\n",
    "        sleep(1)\n",
    "    \n",
    "    result_df = pd.DataFrame({\n",
    "        'text_id': text_ids, \n",
    "        'text': text_list, \n",
    "        'model_responses': model_responses, \n",
    "        'corrected_model_responses': corrected_model_responses, \n",
    "        'true_label': answers\n",
    "    })\n",
    "    return result_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero Shot Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_categories():\n",
    "    train_df = pd.read_excel('train_split.xlsx')\n",
    "    \n",
    "    all_categories = sorted(train_df['label'].unique())\n",
    "    print(\"Found categories:\", all_categories)\n",
    "    print(\"Total categories:\", len(all_categories))\n",
    "    \n",
    "    return all_categories\n",
    "\n",
    "categories = get_all_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_list = get_all_categories()\n",
    "categories_text = \", \".join(categories_list)\n",
    "\n",
    "prompt_prefix_zs = f'''\n",
    "Classify the following Arabic and English text into one of these categories: \n",
    "{categories_text}.\n",
    "\n",
    "Your output should only be one of these exact category names:\n",
    "{chr(10).join(categories_list)}\n",
    "'''\n",
    "\n",
    "prompt_examples_zs = \"Input Text: \"\n",
    "prompt_suffix_zs = \"Output: \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def your_pre_processing_zs(input_string):\n",
    "    return re.sub(r\"@user\",\"\", input_string).strip()\n",
    "\n",
    "def your_post_processing_zs(output_string):\n",
    "    output_clean = output_string.strip().lower()\n",
    "    \n",
    "    if 'business' in output_clean:\n",
    "        return 'business'\n",
    "    elif 'shopping' in output_clean:\n",
    "        return 'shopping'\n",
    "    elif 'finance' in output_clean:\n",
    "        return 'finance'\n",
    "    elif 'education' in output_clean:\n",
    "        return 'education'\n",
    "    elif 'tech' in output_clean or 'technology' in output_clean:\n",
    "        return 'tech'\n",
    "    elif 'sports' in output_clean:\n",
    "        return 'sports'\n",
    "    elif 'medical' in output_clean or 'health' in output_clean:\n",
    "        return 'medical'\n",
    "    else:\n",
    "        return output_string.strip()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_config_zs = {\n",
    "    'max_tokens': 3,\n",
    "    'temperature': 0.4,\n",
    "    'top_p': 0.7,\n",
    "    'stop': []\n",
    "}\n",
    "\n",
    "model = 'llama-3.1-8b-instant'\n",
    "print(model)\n",
    "\n",
    "eval_df = get_eval_df(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = test_range(eval_df, prompt_config_zs, prompt_examples_zs, prompt_prefix_zs, prompt_suffix_zs, pre_processing=your_pre_processing_zs, post_processing=your_post_processing_zs, model=model, debug=False)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(results_df['corrected_model_responses']==results_df['true_label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(results_df['true_label'], results_df['corrected_model_responses'],average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = get_test_set()\n",
    "results_df = test_range(test_df, prompt_config_zs, prompt_examples_zs, prompt_prefix_zs, prompt_suffix_zs, pre_processing=your_pre_processing_zs, post_processing=your_post_processing_zs, model=model, debug=False)\n",
    "results_df.to_csv('zsl_test_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(results_df['true_label'], results_df['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = results_df.set_index(\"text_id\").join(test_df.set_index('id'), lsuffix='_caller', rsuffix='_other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = joined_df.loc[joined_df.codemixed==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(cm['true_label'], cm['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mono = joined_df.loc[joined_df.codemixed==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(mono['true_label'], mono['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few Shot Prompting (In Context Learning)\n",
    "Useful to fix output format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = get_train_df(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_example(row):\n",
    "    line1 = \"Input Text: \" + row['text'] + \"\\n\"\n",
    "    label = row['label']  \n",
    "    line2 = \"Output: \" + label + \"\\n\"\n",
    "    return line1 + line2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_examples_icl = \"\"\n",
    "for idx,row in train_df.iterrows():\n",
    "    ex = create_example(row)\n",
    "    prompt_examples_icl += ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_examples_icl = prompt_examples_icl + \"Input Text: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = get_all_categories()\n",
    "categories_text = \", \".join(categories)\n",
    "\n",
    "prompt_prefix_icl = f'''\n",
    "Classify the following Arabic and English text into one of these categories: \n",
    "{categories_text}.\n",
    "\n",
    "Your output should only be one of these exact category names like in the examples below.\n",
    "'''\n",
    "\n",
    "prompt_suffix_icl = \"Output: \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df = test_range(eval_df, prompt_config_zs, prompt_examples_icl, prompt_prefix_icl, prompt_suffix_icl, pre_processing=your_pre_processing_zs, post_processing=your_post_processing_zs, model=model, debug=False)\n",
    "# print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(results_df['true_label'], results_df['corrected_model_responses'],average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = get_test_set()\n",
    "results_df = test_range(test_df, prompt_config_zs, prompt_examples_icl, prompt_prefix_icl, prompt_suffix_icl, pre_processing=your_pre_processing_zs, post_processing=your_post_processing_zs, model=model, debug=False)\n",
    "results_df.to_csv('icl_test_results_50ex.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(results_df['true_label'], results_df['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = results_df.set_index(\"text_id\").join(test_df.set_index('id'), lsuffix='_caller', rsuffix='_other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = joined_df.loc[joined_df.codemixed==1]\n",
    "mono = joined_df.loc[joined_df.codemixed==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(cm['true_label'], cm['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mono = joined_df.loc[joined_df.codemixed==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(mono['true_label'], mono['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain of Thought Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_texts = [\n",
    "    \"تطوير business strategy فعاله يعتمد علي فهم market trends بشكل شامل ودقيق\",\n",
    "    \"الشركات الناجحة تضع خطط استراتيجية واضحة لتحقيق اهدافها في السوق\"\n",
    "]\n",
    "justification_business = [\n",
    "    \"This text is about business because it discusses company strategies, market analysis, and commercial planning\",\n",
    "    \"This belongs to business category as it focuses on organizational management and market competition\"\n",
    "]\n",
    "\n",
    "education_texts = [\n",
    "    \"في حال تم تطبيق effective curriculum development سيزيد ذلك من مستوي student engagement في الفصول الدراسيه\",\n",
    "    \"استخدام virtual classrooms يعزز فرص collaboration بين الطلاب من مختلف انحاء العالم\"\n",
    "]\n",
    "justification_education = [\n",
    "    \"This text is about education because it mentions curriculum development and student engagement in classrooms\",\n",
    "    \"This belongs to education category as it discusses virtual learning and student collaboration\"\n",
    "]\n",
    "\n",
    "finance_texts = [\n",
    "    \"اذا كنت تريد النجاح في trading عليك ان تتجنب emotional decisions وتركز علي market analysis\",\n",
    "    \"تعتبر fintech من المجالات الرايده حيث تقدم حلولا مبتكره لتحسين banking services\"\n",
    "]\n",
    "justification_finance = [\n",
    "    \"This text is about finance because it covers trading strategies and market analysis\",\n",
    "    \"This belongs to finance category as it discusses fintech innovations and banking services\"\n",
    "]\n",
    "\n",
    "health_texts = [\n",
    "    \"اذا كنت ترغب في تحسين mental health يجب عليك ممارسه mindfulness بانتظام وتناول طعام صحي\",\n",
    "    \"ممارسة الرياضة اليومية تساعد في الحفاظ على صحة القلب والجسم بشكل عام\"\n",
    "]\n",
    "justification_health = [\n",
    "    \"This text is about health because it discusses mental health, mindfulness, and healthy eating\",\n",
    "    \"This belongs to health category as it covers physical exercise and heart health\"\n",
    "]\n",
    "\n",
    "medical_texts = [\n",
    "    \"تعتبر nutrition السليمه اساسا لنجاح اي medical treatment لذا يجب التركيز علي الاطعمه الغنيه بالفيتامينات\",\n",
    "    \"هل يمكن ان توثر pharmaceutical advancements علي نسبه الشفاء من الامراض المزمنه بشكل كبير\"\n",
    "]\n",
    "justification_medical = [\n",
    "    \"This text is about medical because it discusses nutrition in medical treatment and vitamins\",\n",
    "    \"This belongs to medical category as it covers pharmaceutical advancements and chronic disease treatment\"\n",
    "]\n",
    "\n",
    "shopping_texts = [\n",
    "    \"اذا كنت ترغب في شراء consumer electronics فمن الافضل دايما مراجعه customer reviews قبل اتخاذ قرارك\",\n",
    "    \"مقارنة الاسعار بين المتاجر المختلفة تساعد في اتخاذ قرار شراء أفضل\"\n",
    "]\n",
    "justification_shopping = [\n",
    "    \"This text is about shopping because it mentions consumer electronics and customer reviews\",\n",
    "    \"This belongs to shopping category as it discusses price comparison and purchase decisions\"\n",
    "]\n",
    "\n",
    "social_texts = [\n",
    "    \"تفاعل الافراد في المجتمع يساهم في بناء علاقات قوية وتحسين جودة الحياة الاجتماعية\",\n",
    "    \"المبادرات المجتمعية تلعب دوراً هاماً في حل المشكلات الاجتماعية وتعزيز التكافل\"\n",
    "]\n",
    "justification_social = [\n",
    "    \"This text is about social because it discusses community interactions and social relationships\",\n",
    "    \"This belongs to social category as it covers community initiatives and social problem-solving\"\n",
    "]\n",
    "\n",
    "sports_texts = [\n",
    "    \"اللاعبون المميزون في cricket يعرفون كيف يستخدمون strategic planning للفوز بالمباريات المهمه\",\n",
    "    \"التدريب المستمر والالتزام بالبرنامج الرياضي اساسي لتحقيق النتائج في المسابقات\"\n",
    "]\n",
    "justification_sports = [\n",
    "    \"This text is about sports because it mentions cricket players and strategic planning in games\",\n",
    "    \"This belongs to sports category as it discusses continuous training and sports competitions\"\n",
    "]\n",
    "\n",
    "tech_texts = [\n",
    "    \"اذا استثمرت الشركات في cloud computing ستتمكن من تحسين كفاءه عملياتها وتقليل التكاليف\",\n",
    "    \"الذكاء الاصطناعي يساهم في تطوير قطاعات متعددة من الصناعة والخدمات\"\n",
    "]\n",
    "justification_tech = [\n",
    "    \"This text is about tech because it covers cloud computing and operational efficiency\",\n",
    "    \"This belongs to tech category as it discusses artificial intelligence and industry development\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(40)\n",
    "\n",
    "def create_examples(all_texts, all_justifications, all_labels):\n",
    "    examples = []\n",
    "\n",
    "    # Combine all texts, justifications and labels\n",
    "    combined_data = list(zip(all_texts, all_justifications, all_labels))\n",
    "    random.shuffle(combined_data)\n",
    "\n",
    "    for text, justification, label in combined_data:\n",
    "        line1 = \"Input Text: \" + text + \"\\n\"\n",
    "        justification_line = \"Justification: \" + justification + \"\\n\"\n",
    "        line2 = \"Output: \" + label + \"\\n\"\n",
    "        examples.append(line1 + justification_line + line2)\n",
    "\n",
    "    return ''.join(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_topic_texts = (business_texts + education_texts + finance_texts + \n",
    "                   health_texts + medical_texts + shopping_texts + \n",
    "                   social_texts + sports_texts + tech_texts)\n",
    "\n",
    "all_topic_justifications = (justification_business + justification_education + justification_finance +\n",
    "                           justification_health + justification_medical + justification_shopping +\n",
    "                           justification_social + justification_sports + justification_tech)\n",
    "\n",
    "all_topic_labels = (['business'] * len(business_texts) + \n",
    "                   ['education'] * len(education_texts) +\n",
    "                   ['finance'] * len(finance_texts) +\n",
    "                   ['health'] * len(health_texts) +\n",
    "                   ['medical'] * len(medical_texts) +\n",
    "                   ['shopping'] * len(shopping_texts) +\n",
    "                   ['social'] * len(social_texts) +\n",
    "                   ['sports'] * len(sports_texts) +\n",
    "                   ['tech'] * len(tech_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_examples_cot = create_examples(all_topic_texts, all_topic_justifications, all_topic_labels) + \"Input Text: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt_examples_cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_prefix_cot = f'''\n",
    "Classify the following Arabic text into one of these categories: \n",
    "{\", \".join(categories)}.\n",
    "\n",
    "Analyze the text and provide a justification before giving the final category.\n",
    "Your output should include a justification and then the category name like in the examples below.\n",
    "'''\n",
    "\n",
    "prompt_suffix_cot = \"Justification: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def your_pre_processing_cot(input_string):\n",
    "    return input_string.strip()  \n",
    "\n",
    "def your_post_processing_cot(output_string):\n",
    "    categories = ['business', 'education', 'finance', 'health', 'medical', 'shopping', 'social', 'sports', 'tech']\n",
    "    output_lower = output_string.lower()\n",
    "    \n",
    "    for category in categories:\n",
    "        if category in output_lower:\n",
    "            return category\n",
    "    \n",
    "    return output_string.split()[0] if output_string.strip() else 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_config_cot = {'max_tokens': 30,\n",
    "                'temperature': 0.4,\n",
    "                'top_k': 50,\n",
    "                'top_p': 0.7,\n",
    "                'repetition_penalty': 1,\n",
    "                'stop': []}\n",
    "\n",
    "model = 'llama-3.1-8b-instant'\n",
    "print(model)\n",
    "\n",
    "eval_df = get_eval_df(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = test_range(eval_df, prompt_config_cot, prompt_examples_cot, prompt_prefix_cot, prompt_suffix_cot, pre_processing=your_pre_processing_cot, post_processing=your_post_processing_cot, model=model, debug=False)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('error_analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['corrected_model_responses'] = results_df['model_responses'].apply(your_post_processing_cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(results_df['true_label'], results_df['corrected_model_responses'],average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(results_df['true_label'], results_df['corrected_model_responses']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = get_test_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = test_range(test_df, prompt_config_cot, prompt_examples_cot, prompt_prefix_cot, prompt_suffix_cot, pre_processing=your_pre_processing_cot, post_processing=your_post_processing_cot, model=model, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['corrected_model_responses'] = results_df['model_responses'].apply(your_post_processing_cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(results_df['true_label'], results_df['corrected_model_responses']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('test_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = test_range(test_df, prompt_config_cot, prompt_examples_cot, prompt_prefix_cot, prompt_suffix_cot, pre_processing=your_pre_processing_cot, post_processing=your_post_processing_cot, model=model, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['corrected_model_responses'] = results_df['model_responses'].apply(your_post_processing_cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv('test_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(results_df['true_label'], results_df['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = results_df.set_index(\"text_id\").join(test_df.set_index('id'), lsuffix='_caller', rsuffix='_other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = joined_df.loc[joined_df.codemixed==1]\n",
    "mono = joined_df.loc[joined_df.codemixed==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(mono['true_label'], mono['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(cm['true_label'], cm['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOD Set Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is No Data for This\n",
    "def get_ood_set():\n",
    "    ood_df = pd.read_excel('combined.xlsx')\n",
    "    return ood_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_df = get_ood_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'llama-3.1-8b-instant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = test_range(ood_df, prompt_config_cot, prompt_examples_cot, prompt_prefix_cot, prompt_suffix_cot, pre_processing=your_pre_processing_cot, post_processing=your_post_processing_cot, model=model, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['corrected_model_responses'] = results_df['model_responses'].apply(your_post_processing_cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(results_df['true_label'], results_df['corrected_model_responses']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = test_range(ood_df, prompt_config_cot, prompt_examples_cot, prompt_prefix_cot, prompt_suffix_cot, pre_processing=your_pre_processing_cot, post_processing=your_post_processing_cot, model=model, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['corrected_model_responses'] = results_df['model_responses'].apply(your_post_processing_cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('ood_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv('ood_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(results_df['true_label'], results_df['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = results_df.set_index('text_id').join(ood_df.set_index('id'), lsuffix='_caller', rsuffix='_other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgn = joined_df.loc[joined_df['domain']=='religion']\n",
    "gen = joined_df.loc[joined_df['domain']=='gender']\n",
    "ori = joined_df.loc[joined_df['domain']=='orientation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(rgn['offense_caller'], rgn['corrected_model_responses'], digits=4))\n",
    "print(classification_report(gen['offense_caller'], gen['corrected_model_responses'], digits=4))\n",
    "print(classification_report(ori['offense_caller'], ori['corrected_model_responses'], digits=4))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZSL OOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = test_range(ood_df, prompt_config_zs, prompt_examples_zs, prompt_prefix_zs, prompt_suffix_zs, pre_processing=your_pre_processing_zs, post_processing=your_post_processing_zs, model=model, debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('zsl_ood_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = results_df.set_index('text_id').join(ood_df.set_index('id'), lsuffix='_caller', rsuffix='_other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgn = joined_df.loc[joined_df['domain']=='religion']\n",
    "gen = joined_df.loc[joined_df['domain']=='gender']\n",
    "ori = joined_df.loc[joined_df['domain']=='orientation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(rgn['offense_caller'], rgn['corrected_model_responses'], digits=4))\n",
    "print(classification_report(gen['offense_caller'], gen['corrected_model_responses'], digits=4))\n",
    "print(classification_report(ori['offense_caller'], ori['corrected_model_responses'], digits=4))\n",
    "print(classification_report(joined_df['offense_caller'], joined_df['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICL OOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = test_range(ood_df, prompt_config_zs, prompt_examples_icl, prompt_prefix_icl, prompt_suffix_icl, pre_processing=your_pre_processing_zs, post_processing=your_post_processing_zs, model=model, debug=False)\n",
    "results_df.to_csv('icl_ood_results_50ex.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = results_df.set_index('text_id').join(ood_df.set_index('id'), lsuffix='_caller', rsuffix='_other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgn = joined_df.loc[joined_df['domain']=='religion']\n",
    "gen = joined_df.loc[joined_df['domain']=='gender']\n",
    "ori = joined_df.loc[joined_df['domain']=='orientation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(rgn['offense_caller'], rgn['corrected_model_responses'], digits=4))\n",
    "print(classification_report(gen['offense_caller'], gen['corrected_model_responses'], digits=4))\n",
    "print(classification_report(ori['offense_caller'], ori['corrected_model_responses'], digits=4))\n",
    "print(classification_report(joined_df['offense_caller'], joined_df['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
