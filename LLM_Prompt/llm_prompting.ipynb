{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from groq import Groq\n",
    "from time import sleep\n",
    "import re\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dprint(s, debug):\n",
    "    if debug:\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "YOUR_GROQ_API_KEY = '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'  # Get from https://console.groq.com/keys\n",
    "groq_client = Groq(api_key=YOUR_GROQ_API_KEY)\n",
    "\n",
    "def call_groq_api(prompt, student_configs, pre_processing, post_processing, model='llama3-70b-8192', debug=False):\n",
    "    prompt = pre_processing(prompt)\n",
    "    \n",
    "    groq_params = {\n",
    "        'messages': [{'role': 'user', 'content': prompt}],\n",
    "        'model': model,\n",
    "        'max_tokens': student_configs.get('max_tokens', 512),\n",
    "        'temperature': student_configs.get('temperature', 0.7),\n",
    "        'top_p': student_configs.get('top_p', 0.7),\n",
    "        'stop': student_configs.get('stop', None),\n",
    "    }\n",
    "    \n",
    "    output = groq_client.chat.completions.create(**groq_params)\n",
    "    \n",
    "    dprint('*****prompt*****', debug)\n",
    "    dprint(prompt, debug)\n",
    "    dprint('*****result*****', debug)\n",
    "    res = output.choices[0].message.content\n",
    "    dprint(res, debug)\n",
    "    dprint('*****output*****', debug)\n",
    "    labels_only = post_processing(res)\n",
    "    dprint('POST PROCESSED', debug)\n",
    "    dprint(labels_only, debug)\n",
    "    dprint('=========', debug)\n",
    "    return labels_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_names = [\n",
    "#     'togethercomputer/llama-2-7b', #LLaMa-2-7B\n",
    "#     'togethercomputer/llama-2-13b', #LLaMa-2-13B\n",
    "#     'togethercomputer/llama-2-70b', #LLaMa-2-70B\n",
    "#     'togethercomputer/llama-2-70b-chat', #LLaMa-2-70B-Chat\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most likely current Groq model names:\n",
    "model_names = [\n",
    "    'llama-3.1-8b-instant',     \n",
    "    \"llama-3.3-70b-versatile\",              \n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_df(topn = 10):\n",
    "    train_df = pd.read_csv('train.csv')\n",
    "    return train_df[:topn]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_set():\n",
    "    test_df = pd.read_csv('test.csv')\n",
    "    return test_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_df(topn = 5):\n",
    "    eval_df = pd.read_csv('val.csv')\n",
    "    return eval_df.sample(topn)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_range(df, prompt_configs, prompt_prefix, examples, prompt_suffix,\n",
    "               pre_processing=lambda x:x, post_processing=lambda y:y,\n",
    "               model='llama-3.1-8b-instant', debug=False):\n",
    "    tweet_idx = []\n",
    "    answers = []\n",
    "    model_responses = []\n",
    "    corrected_model_responses = []\n",
    "    tweet_txt_list = []\n",
    "    ap_text = \"\"\n",
    "    for idx, row in tqdm(df.iterrows()):\n",
    "        tweet_idx.append(row['id'])\n",
    "        fixed_prompt = row['tweet_text'] + \"\\n\"\n",
    "        tweet_txt_list.append(row['tweet_text'])\n",
    "        fixed_prompt = pre_processing(fixed_prompt)\n",
    "        prompt = prompt_prefix + examples + fixed_prompt + prompt_suffix\n",
    "        answer = row['offense']\n",
    "        answers.append(answer)\n",
    "        model_response = call_groq_api(prompt, prompt_configs, pre_processing, lambda y:y, model=model, debug=debug) \n",
    "        corrected_model_response = post_processing(model_response)\n",
    "        corrected_model_responses.append(corrected_model_response)\n",
    "        model_responses.append(model_response)\n",
    "        sleep(1)\n",
    "    df = pd.DataFrame({'tweet_idx': tweet_idx, 'tweet_text': tweet_txt_list, 'model_responses': model_responses, 'corrected_model_responses':corrected_model_responses, 'offense': answers})\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero Shot Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_prefix_zs = \\\n",
    "'''Offensive speech focuses on the potentially hurtful effect of the tweet content on a given target. This category of text often contains offensive words such as sarcastic remarks, insults, slanders, and slurs.\n",
    "Based on above definition, classify the following Hinglish tweet into offensive speech or not. \n",
    "Your output should only be either \"OFF\" for offensive, or \"NOT\" for not offensive.\n",
    "'''\n",
    "prompt_examples_zs = \"Input Tweet: \"\n",
    "prompt_suffix_zs = \"Output: \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_string: '@user tweet'\n",
    "def your_pre_processing_zs(input_string):\n",
    "    return re.sub(r\"@user\",\"\", input_string).strip()\n",
    "\n",
    "def your_post_processing_zs(output_string):\n",
    "    # using regular expression to find the first consecutive digits in the returned string\n",
    "    if output_string.strip().lower()[:3]=='off':\n",
    "        return 1\n",
    "    elif output_string.strip().lower()[:3]=='not':\n",
    "        return 0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_config_zs = {\n",
    "    'max_tokens': 3,\n",
    "    'temperature': 0.4,\n",
    "    'top_p': 0.7,\n",
    "    'stop': []\n",
    "}\n",
    "\n",
    "model = 'llama-3.1-8b-instant'\n",
    "print(model)\n",
    "\n",
    "eval_df = get_eval_df(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = test_range(eval_df, prompt_config_zs, prompt_examples_zs, prompt_prefix_zs, prompt_suffix_zs, pre_processing=your_pre_processing_zs, post_processing=your_post_processing_zs, model=model, debug=False)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(results_df['corrected_model_responses']==results_df['offense'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(results_df['offense'], results_df['corrected_model_responses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = get_test_set()\n",
    "results_df = test_range(test_df, prompt_config_zs, prompt_examples_zs, prompt_prefix_zs, prompt_suffix_zs, pre_processing=your_pre_processing_zs, post_processing=your_post_processing_zs, model=model, debug=False)\n",
    "results_df.to_csv('zsl_test_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(results_df['offense'], results_df['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = results_df.set_index(\"tweet_idx\").join(test_df.set_index('id'), lsuffix='_caller', rsuffix='_other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = joined_df.loc[joined_df.codemixed==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(cm['offense_caller'], cm['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mono = joined_df.loc[joined_df.codemixed==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(mono['offense_caller'], mono['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few Shot Prompting (In Context Learning)\n",
    "Useful to fix output format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = get_train_df(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_example(row):\n",
    "    line1 = \"Input Tweet: \" + row['tweet_text'] + \"\\n\"\n",
    "    label = 'OFF' if row['offense']==1 else 'NOT'\n",
    "    line2 = \"Output: \" + label + \"\\n\"\n",
    "    return line1+line2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_examples_icl = \"\"\n",
    "for idx,row in train_df.iterrows():\n",
    "    ex = create_example(row)\n",
    "    prompt_examples_icl += ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_examples_icl = prompt_examples_icl + \"Input Tweet: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_prefix_icl = \\\n",
    "'''Offensive speech focuses on the potentially hurtful effect of the tweet content on a given target. This category of text often contains offensive words such as sarcastic remarks, insults, slanders, and slurs.\n",
    "Based on above definition, classify the following Hinglish tweet into offensive speech or not. Your output should only be either \"OFF\" for offensive, or \"NOT\" for not offensive like in the examples below.\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "prompt_suffix_icl = \"Output: \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df = test_range(eval_df, prompt_config_zs, prompt_examples_icl, prompt_prefix_icl, prompt_suffix_icl, pre_processing=your_pre_processing_zs, post_processing=your_post_processing_zs, model=model, debug=False)\n",
    "# print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(results_df['offense'], results_df['corrected_model_responses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = get_test_set()\n",
    "results_df = test_range(test_df, prompt_config_zs, prompt_examples_icl, prompt_prefix_icl, prompt_suffix_icl, pre_processing=your_pre_processing_zs, post_processing=your_post_processing_zs, model=model, debug=False)\n",
    "results_df.to_csv('icl_test_results_50ex.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(results_df['offense'], results_df['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = results_df.set_index(\"tweet_idx\").join(test_df.set_index('id'), lsuffix='_caller', rsuffix='_other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = joined_df.loc[joined_df.codemixed==1]\n",
    "mono = joined_df.loc[joined_df.codemixed==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(cm['offense_caller'], cm['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mono = joined_df.loc[joined_df.codemixed==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(mono['offense_caller'], mono['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain of Thought Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "off_tweets = [\n",
    "\"Ho skta h kuch baudh to teri tarah dogle bhi nhi hote..balki bahut hmare sc ya dalit bhai hmare sath mandiro me jate h khub dharm ko mante hai snatan me viswas krte h..or kuch gaddar meem walo ka gana gate hai..wo acha h lekin jo tum kar rhe ho wo ghtiya h..jai meem bol ab\",\n",
    "\"Kab aana hai ? # Gharwapasi\",\n",
    "\"Haa...Ab Umpire Bhi IPL khelega Chutiya Sala Fixer.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "justification_off_tweets = [\"This tweet is offensive because it is insulting in nature\", \"This tweet is offensive due to the the context of Ghar Wapasi which involves religious conversions\", \"This tweet is offensive as it insults the umpire and uses cuss words.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_off_tweets = [\"I don't understand why ppl take law in hands...agar chor tha toh police complaint hone thee...bekar me moka diya jata h ke dalit exploitation ho raha h...\", \"I have of hindus crimes data agints dalit u hater.\\\n",
    "Dalit hater community.\\\n",
    "Do u have data to prove me otherwise and provide data for muslim crime against hindu\", \"#demonetisation  .. mention bigger scam than this 😂😂\",\n",
    "\"Can he himself come to court room in an himachali outfit or in an pure old adivasi dress(no dress)...\",\n",
    "\"Just like modi said corruption will end with demonetisation\\\n",
    "15 L will be in everyone's account \\\n",
    "2 million jobs every year \\\n",
    "USA will stand in line for visa etc \\\n",
    "Aap &amp; bjpeee are the two sides of lies &amp; deceit\", \"Romanticizing open defecation under heavy rain to enjoy the melancholy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "justification_non_off_tweets = [\"This tweet is not offensive as it is against lynching of individuals\", \"This tweet is not offensive as it just asks for more data\", \"This tweet is not offensive as it criticizes a government policy which is allowed in a healthy democracy\",\n",
    "                                \"This tweet is not offensive as it is in fact showcasing cultural diversity and not containing offensive language\",\n",
    "                                \"This tweet is not offensive as even though it is critical of political promises, it simply expresses a perspective on political issues.\", \"This tweet is not offensive despite the sarcasm, because it is satirical in nature without offending any group in particular\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(40)\n",
    "def create_examples(off_tweets, justification_off_tweets, non_off_tweets, justification_non_off_tweets):\n",
    "    examples = []\n",
    "\n",
    "    combined_tweets = list(zip(off_tweets, justification_off_tweets, ['OFF'] * len(off_tweets))) + \\\n",
    "                      list(zip(non_off_tweets, justification_non_off_tweets, ['NOT'] * len(non_off_tweets)))\n",
    "\n",
    "    random.shuffle(combined_tweets)\n",
    "\n",
    "    for tweet, justification, label in combined_tweets:\n",
    "        line1 = \"Input Tweet: \" + tweet + \"\\n\"\n",
    "        justification_line = \"Justification: \" + justification + \"\\n\"\n",
    "        line2 = \"Output: \" + label + \"\\n\"\n",
    "        examples.append(line1 + justification_line + line2)\n",
    "\n",
    "    return ''.join(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_examples(off_tweets, justification_off_tweets, non_off_tweets, justification_non_off_tweets):\n",
    "#     examples = \"\"\n",
    "#     for i in range(len(off_tweets)):\n",
    "#         line1 = \"Input Tweet: \" + off_tweets[i] + \"\\n\"\n",
    "#         justification_off = \"Justification: \" + justification_off_tweets[i] + \"\\n\"\n",
    "#         line2 = \"Output: \" + 'OFF' + \"\\n\"\n",
    "#         line3 = \"Input Tweet: \" + non_off_tweets[i] + \"\\n\"\n",
    "#         justification_not = \"Justification: \" + justification_non_off_tweets[i] + \"\\n\"\n",
    "#         line4 = \"Output: \" + 'NOT' + \"\\n\"\n",
    "#         set = line1 + justification_off + line2 + line3 + justification_not + line4\n",
    "#         examples+=set\n",
    "    \n",
    "#     return examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_examples_cot = create_examples(off_tweets, justification_off_tweets, non_off_tweets, justification_non_off_tweets) + \"Input Tweet: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt_examples_cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_prefix_cot = \\\n",
    "'''Offensive speech focuses on the potentially hurtful effect of the tweet content on a given target. This category of text often contains offensive words such as sarcastic remarks, insults, slanders, and slurs.\n",
    "Based on above definition, classify the following Hinglish tweet into offensive speech or not. Your output should be a only be either \"OFF\" for offensive, or \"NOT\" for not offensive along with a justification for your output like in the examples below.\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "prompt_suffix_cot = \"Justification: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_string: '@user tweet'\n",
    "def your_pre_processing_cot(input_string):\n",
    "    return re.sub(r\"@user\",\"\", input_string).strip()\n",
    "\n",
    "def your_post_processing_cot(output_string):\n",
    "    # using regular expression to find the first consecutive digits in the returned string\n",
    "    if output_string.find(\"not offensive\")!=-1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_config_cot = {'max_tokens': 30,\n",
    "                'temperature': 0.4,\n",
    "                'top_k': 50,\n",
    "                'top_p': 0.7,\n",
    "                'repetition_penalty': 1,\n",
    "                'stop': []}\n",
    "\n",
    "model = 'llama-3.1-8b-instant'\n",
    "print(model)\n",
    "\n",
    "eval_df = get_eval_df(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = test_range(eval_df, prompt_config_cot, prompt_examples_cot, prompt_prefix_cot, prompt_suffix_cot, pre_processing=your_pre_processing_cot, post_processing=your_post_processing_cot, model=model, debug=False)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('error_analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['corrected_model_responses'] = results_df['model_responses'].apply(your_post_processing_cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(results_df['offense'], results_df['corrected_model_responses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(results_df['offense'], results_df['corrected_model_responses']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = get_test_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = test_range(test_df, prompt_config_cot, prompt_examples_cot, prompt_prefix_cot, prompt_suffix_cot, pre_processing=your_pre_processing_cot, post_processing=your_post_processing_cot, model=model, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['corrected_model_responses'] = results_df['model_responses'].apply(your_post_processing_cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(results_df['offense'], results_df['corrected_model_responses']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('test_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = test_range(test_df, prompt_config_cot, prompt_examples_cot, prompt_prefix_cot, prompt_suffix_cot, pre_processing=your_pre_processing_cot, post_processing=your_post_processing_cot, model=model, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['corrected_model_responses'] = results_df['model_responses'].apply(your_post_processing_cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv('test_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(results_df['offense'], results_df['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = results_df.set_index(\"tweet_idx\").join(test_df.set_index('id'), lsuffix='_caller', rsuffix='_other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = joined_df.loc[joined_df.codemixed==1]\n",
    "mono = joined_df.loc[joined_df.codemixed==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(mono['offense_caller'], mono['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(cm['offense_caller'], cm['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOD Set Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is No Data for This\n",
    "def get_ood_set():\n",
    "    ood_df = pd.read_csv('cm_hate_combined.csv')\n",
    "    return ood_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_df = get_ood_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_df['tweet_text'] = ood_df['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'llama-3.1-8b-instant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = test_range(ood_df, prompt_config_cot, prompt_examples_cot, prompt_prefix_cot, prompt_suffix_cot, pre_processing=your_pre_processing_cot, post_processing=your_post_processing_cot, model=model, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['corrected_model_responses'] = results_df['model_responses'].apply(your_post_processing_cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(results_df['offense'], results_df['corrected_model_responses']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = test_range(ood_df, prompt_config_cot, prompt_examples_cot, prompt_prefix_cot, prompt_suffix_cot, pre_processing=your_pre_processing_cot, post_processing=your_post_processing_cot, model=model, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['corrected_model_responses'] = results_df['model_responses'].apply(your_post_processing_cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('ood_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv('ood_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(results_df['offense'], results_df['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = results_df.set_index('tweet_idx').join(ood_df.set_index('id'), lsuffix='_caller', rsuffix='_other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgn = joined_df.loc[joined_df['domain']=='religion']\n",
    "gen = joined_df.loc[joined_df['domain']=='gender']\n",
    "ori = joined_df.loc[joined_df['domain']=='orientation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(rgn['offense_caller'], rgn['corrected_model_responses'], digits=4))\n",
    "print(classification_report(gen['offense_caller'], gen['corrected_model_responses'], digits=4))\n",
    "print(classification_report(ori['offense_caller'], ori['corrected_model_responses'], digits=4))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZSL OOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = test_range(ood_df, prompt_config_zs, prompt_examples_zs, prompt_prefix_zs, prompt_suffix_zs, pre_processing=your_pre_processing_zs, post_processing=your_post_processing_zs, model=model, debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('zsl_ood_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = results_df.set_index('tweet_idx').join(ood_df.set_index('id'), lsuffix='_caller', rsuffix='_other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgn = joined_df.loc[joined_df['domain']=='religion']\n",
    "gen = joined_df.loc[joined_df['domain']=='gender']\n",
    "ori = joined_df.loc[joined_df['domain']=='orientation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(rgn['offense_caller'], rgn['corrected_model_responses'], digits=4))\n",
    "print(classification_report(gen['offense_caller'], gen['corrected_model_responses'], digits=4))\n",
    "print(classification_report(ori['offense_caller'], ori['corrected_model_responses'], digits=4))\n",
    "print(classification_report(joined_df['offense_caller'], joined_df['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICL OOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = test_range(ood_df, prompt_config_zs, prompt_examples_icl, prompt_prefix_icl, prompt_suffix_icl, pre_processing=your_pre_processing_zs, post_processing=your_post_processing_zs, model=model, debug=False)\n",
    "results_df.to_csv('icl_ood_results_50ex.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = results_df.set_index('tweet_idx').join(ood_df.set_index('id'), lsuffix='_caller', rsuffix='_other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgn = joined_df.loc[joined_df['domain']=='religion']\n",
    "gen = joined_df.loc[joined_df['domain']=='gender']\n",
    "ori = joined_df.loc[joined_df['domain']=='orientation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(rgn['offense_caller'], rgn['corrected_model_responses'], digits=4))\n",
    "print(classification_report(gen['offense_caller'], gen['corrected_model_responses'], digits=4))\n",
    "print(classification_report(ori['offense_caller'], ori['corrected_model_responses'], digits=4))\n",
    "print(classification_report(joined_df['offense_caller'], joined_df['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
