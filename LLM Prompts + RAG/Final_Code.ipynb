{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d0ca7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from groq import Groq\n",
    "from time import sleep\n",
    "import re\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "import random\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6892a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a Function to Debug and get the result of the Model or The Technique\n",
    "def dprint(s, debug):\n",
    "    if debug:\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7fcc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "YOUR_GROQ_API_KEY = ''  # Get from https://console.groq.com/keys\n",
    "groq_client = Groq(api_key=YOUR_GROQ_API_KEY)\n",
    "\n",
    "def call_groq_api(prompt, student_configs, pre_processing, post_processing, model='llama3-70b-8192', debug=False):\n",
    "    prompt = pre_processing(prompt)\n",
    "    # Initlize the defualt Parameters or Configrations for Groq API \n",
    "    groq_params = {\n",
    "        'messages': [{'role': 'user', 'content': prompt}],\n",
    "        'model': model,\n",
    "        'max_tokens': student_configs.get('max_tokens', 512),\n",
    "        'temperature': student_configs.get('temperature', 0.7),\n",
    "        'top_p': student_configs.get('top_p', 0.7),\n",
    "        'stop': student_configs.get('stop', None),\n",
    "    }\n",
    "    \n",
    "    output = groq_client.chat.completions.create(**groq_params)\n",
    "    \n",
    "    dprint('*****prompt*****', debug)\n",
    "    dprint(prompt, debug)\n",
    "    dprint('*****result*****', debug)\n",
    "    res = output.choices[0].message.content\n",
    "    dprint(res, debug)\n",
    "    dprint('*****output*****', debug)\n",
    "    labels_only = post_processing(res)\n",
    "    dprint('POST PROCESSED', debug)\n",
    "    dprint(labels_only, debug)\n",
    "    dprint('=========', debug)\n",
    "    return labels_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fab787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most likely current Groq model names:\n",
    "model_names = [\n",
    "    'llama-3.1-8b-instant',     \n",
    "    \"llama-3.3-70b-versatile\",  # The Model We Use            \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1357931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_df(topn = 10):\n",
    "    train_df = pd.read_excel('train_split.xlsx')\n",
    "    return train_df.sampl(topn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5489fe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_set(topn=10):\n",
    "    test_df = pd.read_excel('test_split.xlsx')\n",
    "    return test_df.sample(topn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99faff91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_df(topn = 5):\n",
    "    eval_df = pd.read_excel('dev_split.xlsx')\n",
    "    return eval_df.sample(topn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9927d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Model Function with the the Data Labels and Model Answers and prepare Data Frame for Report \n",
    "def test_range(df, prompt_configs, prompt_prefix, examples, prompt_suffix,\n",
    "               pre_processing=lambda x:x, post_processing=lambda y:y,\n",
    "               model='llama-3.3-70b-versatile', debug=False):\n",
    "    text_ids = []\n",
    "    answers = []\n",
    "    model_responses = []\n",
    "    corrected_model_responses = []\n",
    "    text_list = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows()):\n",
    "        text_ids.append(idx)  \n",
    "        fixed_prompt = row['text'] + \"\\n\"\n",
    "        text_list.append(row['text'])\n",
    "        fixed_prompt = pre_processing(fixed_prompt)\n",
    "        prompt = prompt_prefix + examples + fixed_prompt + prompt_suffix\n",
    "        answer = row['label']\n",
    "        answers.append(answer)\n",
    "        model_response = call_groq_api(prompt, prompt_configs, pre_processing, lambda y:y, model=model, debug=debug) \n",
    "        corrected_model_response = post_processing(model_response)\n",
    "        corrected_model_responses.append(corrected_model_response)\n",
    "        model_responses.append(model_response)\n",
    "        sleep(1)\n",
    "    \n",
    "    result_df = pd.DataFrame({\n",
    "        'text_id': text_ids, \n",
    "        'text': text_list, \n",
    "        'model_responses': model_responses, \n",
    "        'corrected_model_responses': corrected_model_responses, \n",
    "        'true_label': answers\n",
    "    })\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031c1ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get The Data With The Number or Rows we will test on it from Evaloation Data\n",
    "data=get_eval_df(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fad9cd",
   "metadata": {},
   "source": [
    "## Zero Shot Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f481c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the categories in The Data\n",
    "def get_all_categories():\n",
    "    train_df = pd.read_excel('train_split.xlsx')\n",
    "    \n",
    "    all_categories = sorted(train_df['label'].unique())\n",
    "    print(\"Found categories:\", all_categories)\n",
    "    print(\"Total categories:\", len(all_categories))\n",
    "    \n",
    "    return all_categories\n",
    "\n",
    "categories = get_all_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f2e444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare The Prompt For Zero Shot \n",
    "categories_list = get_all_categories()\n",
    "categories_text = \", \".join(categories_list)\n",
    "\n",
    "prompt_prefix_zs = f'''\n",
    "Classify the following Combiend Arabic and English text into one of these categories: \n",
    "{categories_text}.\n",
    "\n",
    "Your output should only be one of these exact category names:\n",
    "{chr(10).join(categories_list)}\n",
    "'''\n",
    "\n",
    "prompt_examples_zs = \"Input Text: \"\n",
    "prompt_suffix_zs = \"Output: \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db44652d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre and Post Processing for The Output \n",
    "def your_pre_processing_zs(input_string):\n",
    "    return re.sub(r\"@user\",\"\", input_string).strip()\n",
    "\n",
    "def your_post_processing_zs(output_string):\n",
    "    output_clean = output_string.strip().lower()\n",
    "    \n",
    "    if 'business' in output_clean:\n",
    "        return 'business'\n",
    "    elif 'shopping' in output_clean:\n",
    "        return 'shopping'\n",
    "    elif 'finance' in output_clean:\n",
    "        return 'finance'\n",
    "    elif 'education' in output_clean:\n",
    "        return 'education'\n",
    "    elif 'tech' in output_clean :\n",
    "        return 'tech'\n",
    "    elif 'technology' in output_clean or \"tech\" in output_clean:\n",
    "        return 'tech'\n",
    "    elif 'sports' in output_clean:\n",
    "        return 'sports'\n",
    "    elif 'medical' in output_clean :\n",
    "        return 'medical'\n",
    "    elif  'social' in output_clean:\n",
    "        return 'social'\n",
    "    else:\n",
    "        return output_string.strip()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791aa2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configration for Zeroshot Technique\n",
    "prompt_config_zs = {\n",
    "    'max_tokens': 3,\n",
    "    'temperature': 0.4,\n",
    "    'top_p': 0.7,\n",
    "    'stop': []\n",
    "}\n",
    "\n",
    "model = 'llama-3.3-70b-versatile'\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5f3f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test The Technique\n",
    "results_df = test_range(data, prompt_config_zs, prompt_examples_zs, prompt_prefix_zs, prompt_suffix_zs, pre_processing=your_pre_processing_zs, post_processing=your_post_processing_zs, model=model, debug=False)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55978797",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(results_df['true_label'], results_df['corrected_model_responses'],average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffa4671",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(results_df['true_label'], results_df['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4db661e",
   "metadata": {},
   "source": [
    "## Few Shot Prompting (In Context Learning)\n",
    "Useful to fix output format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d00f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = get_train_df(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1686d2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Examples Data From Our Orignal Data\n",
    "def create_example(row):\n",
    "    line1 = \"Input Text: \" + row['text'] + \"\\n\"\n",
    "    label = row['label']  \n",
    "    line2 = \"Output: \" + label + \"\\n\"\n",
    "    return line1 + line2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e08a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_examples_icl = \"\"\n",
    "for idx,row in train_df.iterrows():\n",
    "    ex = create_example(row)\n",
    "    prompt_examples_icl += ex\n",
    "prompt_examples_icl = prompt_examples_icl + \"Input Text: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d48548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare The Prompt For Few Shot \n",
    "categories = get_all_categories()\n",
    "categories_text = \", \".join(categories)\n",
    "\n",
    "prompt_prefix_icl = f'''\n",
    "Classify the following Combined Arabic and English text into one of these categories: \n",
    "{categories_text}.\n",
    "\n",
    "Your output should only be one of these exact category names like in the examples below.\n",
    "'''\n",
    "\n",
    "prompt_suffix_icl = \"Output: \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab6ee20",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_config_fs = {\n",
    "    'max_tokens': 3,\n",
    "    'temperature': 0.4,\n",
    "    'top_p': 0.7,\n",
    "    'stop': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2d6e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = test_range(data, prompt_config_fs, prompt_examples_icl, prompt_prefix_icl, prompt_suffix_icl, pre_processing=your_pre_processing_zs, post_processing=your_post_processing_zs, model=model, debug=False)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e4cfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(results_df['true_label'], results_df['corrected_model_responses'],average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9055cbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(results_df['true_label'], results_df['corrected_model_responses'], digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c100f8a9",
   "metadata": {},
   "source": [
    "## Chain of Thought Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43824845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text And Justification for each Category in The Data Manual Written\n",
    "business_texts = [\n",
    "    \"تطوير business strategy فعاله يعتمد علي فهم market trends بشكل شامل ودقيق\",\n",
    "    \"الشركات الناجحة تضع خطط استراتيجية واضحة لتحقيق اهدافها في السوق\"\n",
    "]\n",
    "justification_business = [\n",
    "    \"This text is about business because it discusses company strategies, market analysis, and commercial planning\",\n",
    "    \"This belongs to business category as it focuses on organizational management and market competition\"\n",
    "]\n",
    "\n",
    "education_texts = [\n",
    "    \"في حال تم تطبيق effective curriculum development سيزيد ذلك من مستوي student engagement في الفصول الدراسيه\",\n",
    "    \"استخدام virtual classrooms يعزز فرص collaboration بين الطلاب من مختلف انحاء العالم\"\n",
    "]\n",
    "justification_education = [\n",
    "    \"This text is about education because it mentions curriculum development and student engagement in classrooms\",\n",
    "    \"This belongs to education category as it discusses virtual learning and student collaboration\"\n",
    "]\n",
    "\n",
    "finance_texts = [\n",
    "    \"اذا كنت تريد النجاح في trading عليك ان تتجنب emotional decisions وتركز علي market analysis\",\n",
    "    \"تعتبر fintech من المجالات الرايده حيث تقدم حلولا مبتكره لتحسين banking services\"\n",
    "]\n",
    "justification_finance = [\n",
    "    \"This text is about finance because it covers trading strategies and market analysis\",\n",
    "    \"This belongs to finance category as it discusses fintech innovations and banking services\"\n",
    "]\n",
    "\n",
    "health_texts = [\n",
    "    \"اذا كنت ترغب في تحسين mental health يجب عليك ممارسه mindfulness بانتظام وتناول طعام صحي\",\n",
    "    \"ممارسة الرياضة اليومية تساعد في الحفاظ على صحة القلب والجسم بشكل عام\"\n",
    "]\n",
    "justification_health = [\n",
    "    \"This text is about health because it discusses mental health, mindfulness, and healthy eating\",\n",
    "    \"This belongs to health category as it covers physical exercise and heart health\"\n",
    "]\n",
    "\n",
    "medical_texts = [\n",
    "    \"تعتبر nutrition السليمه اساسا لنجاح اي medical treatment لذا يجب التركيز علي الاطعمه الغنيه بالفيتامينات\",\n",
    "    \"هل يمكن ان توثر pharmaceutical advancements علي نسبه الشفاء من الامراض المزمنه بشكل كبير\"\n",
    "]\n",
    "justification_medical = [\n",
    "    \"This text is about medical because it discusses nutrition in medical treatment and vitamins\",\n",
    "    \"This belongs to medical category as it covers pharmaceutical advancements and chronic disease treatment\"\n",
    "]\n",
    "\n",
    "shopping_texts = [\n",
    "    \"اذا كنت ترغب في شراء consumer electronics فمن الافضل دايما مراجعه customer reviews قبل اتخاذ قرارك\",\n",
    "    \"مقارنة الاسعار بين المتاجر المختلفة تساعد في اتخاذ قرار شراء أفضل\"\n",
    "]\n",
    "justification_shopping = [\n",
    "    \"This text is about shopping because it mentions consumer electronics and customer reviews\",\n",
    "    \"This belongs to shopping category as it discusses price comparison and purchase decisions\"\n",
    "]\n",
    "\n",
    "social_texts = [\n",
    "    \"تفاعل الافراد في المجتمع يساهم في بناء علاقات قوية وتحسين جودة الحياة الاجتماعية\",\n",
    "    \"المبادرات المجتمعية تلعب دوراً هاماً في حل المشكلات الاجتماعية وتعزيز التكافل\"\n",
    "]\n",
    "justification_social = [\n",
    "    \"This text is about social because it discusses community interactions and social relationships\",\n",
    "    \"This belongs to social category as it covers community initiatives and social problem-solving\"\n",
    "]\n",
    "\n",
    "sports_texts = [\n",
    "    \"اللاعبون المميزون في cricket يعرفون كيف يستخدمون strategic planning للفوز بالمباريات المهمه\",\n",
    "    \"التدريب المستمر والالتزام بالبرنامج الرياضي اساسي لتحقيق النتائج في المسابقات\"\n",
    "]\n",
    "justification_sports = [\n",
    "    \"This text is about sports because it mentions cricket players and strategic planning in games\",\n",
    "    \"This belongs to sports category as it discusses continuous training and sports competitions\"\n",
    "]\n",
    "\n",
    "tech_texts = [\n",
    "    \"اذا استثمرت الشركات في cloud computing ستتمكن من تحسين كفاءه عملياتها وتقليل التكاليف\",\n",
    "    \"الذكاء الاصطناعي يساهم في تطوير قطاعات متعددة من الصناعة والخدمات\"\n",
    "]\n",
    "justification_tech = [\n",
    "    \"This text is about tech because it covers cloud computing and operational efficiency\",\n",
    "    \"This belongs to tech category as it discusses artificial intelligence and industry development\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0beedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Examples from Text And Justifications\n",
    "def create_examples(all_texts, all_justifications, all_labels):\n",
    "    examples = []\n",
    "\n",
    "    combined_data = list(zip(all_texts, all_justifications, all_labels))\n",
    "    random.shuffle(combined_data)\n",
    "\n",
    "    for text, justification, label in combined_data:\n",
    "        line1 = \"Input Text: \" + text + \"\\n\"\n",
    "        justification_line = \"Justification: \" + justification + \"\\n\"\n",
    "        line2 = \"Output: \" + label + \"\\n\"\n",
    "        examples.append(line1 + justification_line + line2)\n",
    "\n",
    "    return ''.join(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0b98fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine The Text And The Justification \n",
    "all_topic_texts = (business_texts + education_texts + finance_texts + \n",
    "                   health_texts + medical_texts + shopping_texts + \n",
    "                   social_texts + sports_texts + tech_texts)\n",
    "\n",
    "all_topic_justifications = (justification_business + justification_education + justification_finance +\n",
    "                           justification_health + justification_medical + justification_shopping +\n",
    "                           justification_social + justification_sports + justification_tech)\n",
    "\n",
    "all_topic_labels = (['business'] * len(business_texts) + \n",
    "                   ['education'] * len(education_texts) +\n",
    "                   ['finance'] * len(finance_texts) +\n",
    "                   ['health'] * len(health_texts) +\n",
    "                   ['medical'] * len(medical_texts) +\n",
    "                   ['shopping'] * len(shopping_texts) +\n",
    "                   ['social'] * len(social_texts) +\n",
    "                   ['sports'] * len(sports_texts) +\n",
    "                   ['tech'] * len(tech_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0c0053",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_examples_cot = create_examples(all_topic_texts, all_topic_justifications, all_topic_labels) + \"Input Text: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a832996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt_examples_cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afe2bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare The Prompt For Chain of Thoughts \n",
    "\n",
    "prompt_prefix_cot = f'''\n",
    "Classify the following Combined Arabic and English text into one of these categories: \n",
    "{\", \".join(categories)}.\n",
    "\n",
    "Analyze the text and provide a justification before giving the final category.\n",
    "Your output should include a justification and then the category name like in the examples below.\n",
    "'''\n",
    "\n",
    "prompt_suffix_cot = \"Justification: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4574e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre and post Processing for Chain of Thoughts\n",
    "def your_pre_processing_cot(input_string):\n",
    "    return input_string.strip()  \n",
    "\n",
    "def your_post_processing_cot(output_string):\n",
    "    categories = ['business', 'education', 'finance', 'health', 'medical', 'shopping', 'social', 'sports', 'tech']\n",
    "    output_lower = output_string.lower()\n",
    "    \n",
    "    for category in categories:\n",
    "        if category in output_lower:\n",
    "            return category\n",
    "    \n",
    "    return output_string.split()[0] if output_string.strip() else 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce876e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain of Thoughts Technique Configration\n",
    "prompt_config_cot = {\n",
    "    'max_tokens': 80,  \n",
    "    'temperature': 0.2, \n",
    "    'top_k': 0,       \n",
    "    'top_p': 0.9,\n",
    "    'repetition_penalty': 1,\n",
    "    'stop': ['\\nCategory:'] \n",
    "}\n",
    "model = 'llama-3.3-70b-versatile'\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387ce914",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = test_range(data, prompt_config_cot, prompt_examples_cot, prompt_prefix_cot, prompt_suffix_cot, pre_processing=your_pre_processing_cot, post_processing=your_post_processing_cot, model=model, debug=False)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb499830",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(results_df['true_label'], results_df['corrected_model_responses'],average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a14009",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(results_df['true_label'], results_df['corrected_model_responses']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2fb307",
   "metadata": {},
   "source": [
    "## CARP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832ce744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the featuers or key words for each Category\n",
    "category_features = {\n",
    "    'business': ['company strategies', 'market analysis', 'commercial planning', 'business growth', 'market trends'],\n",
    "    'education': ['learning', 'teaching', 'curriculum', 'students', 'school', 'education', 'classroom', 'virtual learning'],\n",
    "    'finance': ['money', 'investment', 'trading', 'banking', 'financial', 'markets', 'fintech', 'economic'],\n",
    "    'health': ['fitness', 'wellness', 'mental health', 'exercise', 'healthy lifestyle', 'physical health'],\n",
    "    'medical': ['treatment', 'medicine', 'pharmaceutical', 'medical care', 'doctors', 'nutrition', 'vitamins'],\n",
    "    'shopping': ['purchase', 'buying', 'products', 'reviews', 'price comparison', 'consumer', 'customer'],\n",
    "    'social': ['community', 'relationships', 'social interactions', 'society', 'social life', 'community initiatives'],\n",
    "    'sports': ['athletes', 'games', 'training', 'competitions', 'sports', 'cricket', 'players', 'matches'],\n",
    "    'tech': ['technology', 'software', 'computers', 'AI', 'digital', 'innovation', 'cloud computing', 'artificial intelligence']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5ae39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Examples Prompt to Show The keyword for each category to the model\n",
    "def create_carp_examples_format(all_texts, all_justifications, all_labels, category_features):\n",
    "\n",
    "    examples = []\n",
    "    combined_data = list(zip(all_texts, all_justifications, all_labels))\n",
    "    \n",
    "    example_subset = combined_data[:6] \n",
    "    \n",
    "    for text, justification, label in example_subset:\n",
    "        features = category_features.get(label, [])\n",
    "        \n",
    "        carp_justification = f\"{justification} CARP Reasoning: Text contains features like {', '.join(features[:2])} confirming {label} category.\"\n",
    "        \n",
    "        line1 = \"Input Text: \" + text + \"\\n\"\n",
    "        justification_line = \"Justification: \" + carp_justification + \"\\n\"\n",
    "        line2 = \"Output: \" + label + \"\\n\"\n",
    "        examples.append(line1 + justification_line + line2)\n",
    "\n",
    "    return ''.join(examples)\n",
    "\n",
    "prompt_examples_carp = create_carp_examples_format(all_topic_texts, all_topic_justifications, all_topic_labels, category_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c63d09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The prompt for CARP\n",
    "prompt_prefix_carp = f\"\"\"\n",
    "Classify the following Combined Arabic and English text into one of these categories:\n",
    "{\", \".join(category_features.keys())}.\n",
    "\n",
    "Use the CARP method internally (analyze topic, list expected features, verify features, decide), \n",
    "but **do NOT show your reasoning**.\n",
    "\n",
    "Output format: Only write the final category name with no explanation, no extra text, and no punctuation.\n",
    "\"\"\"\n",
    "prompt_suffix_carp = \"Justification: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502b0ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre and post processing for CARP\n",
    "def your_pre_processing_carp(input_string):\n",
    "    return input_string.strip()\n",
    "\n",
    "def your_post_processing_carp(output_string):\n",
    "\n",
    "    categories = list(category_features.keys())\n",
    "    output_lower = output_string.lower()\n",
    "    \n",
    "    if \"output:\" in output_lower:\n",
    "        output_part = output_lower.split(\"output:\")[1].strip()\n",
    "        for category in categories:\n",
    "            if category in output_part.split()[0]:  \n",
    "                return category\n",
    "    \n",
    "    for category in categories:\n",
    "        if f\" {category} \" in f\" {output_lower} \":\n",
    "            return category\n",
    "    \n",
    "    return output_string.split()[0] if output_string.strip() else 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650b4cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARP Configrations\n",
    "prompt_config_carp = {\n",
    "    'max_tokens': 150,  \n",
    "    'temperature': 0.1,  \n",
    "    'top_k': 0,       \n",
    "    'top_p': 0.9,\n",
    "    'repetition_penalty': 1.1, \n",
    "    'stop': ['\\n---', 'Input Text:']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a67ab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = test_range(data, prompt_config_carp, prompt_examples_carp, prompt_prefix_carp, prompt_suffix_carp, pre_processing=your_pre_processing_carp, post_processing=your_post_processing_carp, model=model, debug=False)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b01912",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(results_df['true_label'], results_df['corrected_model_responses'],average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ded76ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(results_df['true_label'], results_df['corrected_model_responses']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a39ffd",
   "metadata": {},
   "source": [
    "# self consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f7dbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Majority Vote Function To Get The Counter for each predict output for each COT and decide the final answer\n",
    "def majority_vote(predictions):\n",
    "    from collections import Counter\n",
    "    \n",
    "    if not predictions:\n",
    "        return 'unknown'    \n",
    "    prediction_counts = Counter(predictions)\n",
    "    most_common = prediction_counts.most_common()\n",
    "    \n",
    "    if len(most_common) == 1:\n",
    "        return most_common[0][0]\n",
    "    else:\n",
    "        return most_common[0][0]\n",
    "# pre procissing for Self Consistency\n",
    "def self_consistency_post_processing(output_string):\n",
    "\n",
    "    categories = ['business', 'education', 'finance', 'health', 'medical', \n",
    "                 'shopping', 'social', 'sports', 'tech']\n",
    "    \n",
    "    output_lower = output_string.lower()\n",
    "    final_answer_patterns = [\n",
    "        'final answer:',\n",
    "        'answer:',\n",
    "        'category:',\n",
    "        'classification:'\n",
    "    ]\n",
    "    \n",
    "    for pattern in final_answer_patterns:\n",
    "        if pattern in output_lower:\n",
    "            parts = output_lower.split(pattern, 1)\n",
    "            if len(parts) > 1:\n",
    "                answer_text = parts[1].strip()\n",
    "                for category in categories:\n",
    "                    if category in answer_text.split()[0] if answer_text else False:\n",
    "                        return category\n",
    "    \n",
    "    for category in categories:\n",
    "        if f\" {category} \" in f\" {output_lower} \":\n",
    "            return category\n",
    "    \n",
    "    return output_string.split()[0] if output_string.strip() else 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6100e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare The Prompt way for Self Consistency The way of Output and the Defualt Conigrations and API Parameters\n",
    "# and prepare The numbers of samples of tries with different COT \n",
    "def self_consistency_prompting(df, prompt_config, prompt_prefix, examples, prompt_suffix,\n",
    "                             pre_processing=lambda x:x, post_processing=lambda y:y,\n",
    "                             model='llama-3.3-70b-versatile', \n",
    "                             num_samples=3, \n",
    "                             debug=False):\n",
    "\n",
    "    \n",
    "    text_ids = []\n",
    "    answers = []\n",
    "    all_model_responses = []  \n",
    "    final_predictions = []    \n",
    "    text_list = []\n",
    "    individual_predictions_list = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows()):\n",
    "        text_ids.append(idx)\n",
    "        fixed_prompt = row['text'] + \"\\n\"\n",
    "        text_list.append(row['text'])\n",
    "        fixed_prompt = pre_processing(fixed_prompt)\n",
    "        \n",
    "        reasoning_prompt = prompt_prefix + examples + fixed_prompt + prompt_suffix\n",
    "        \n",
    "        answer = row['label']\n",
    "        answers.append(answer)\n",
    "        \n",
    "        reasoning_samples = []\n",
    "        predictions = []\n",
    "        \n",
    "        for sample_num in range(num_samples):\n",
    "            sample_config = prompt_config.copy()\n",
    "            sample_config['temperature'] = min(0.8, prompt_config.get('temperature', 0.7) + 0.1 * sample_num)\n",
    "            \n",
    "            model_response = call_groq_api(\n",
    "                reasoning_prompt, \n",
    "                sample_config, \n",
    "                pre_processing, \n",
    "                lambda y: y, \n",
    "                model=model, \n",
    "                debug=debug\n",
    "            )\n",
    "            \n",
    "            reasoning_samples.append(model_response)\n",
    "            \n",
    "            prediction = post_processing(model_response)\n",
    "            predictions.append(prediction)\n",
    "            \n",
    "            sleep(0.5)  \n",
    "        \n",
    "        final_prediction = majority_vote(predictions)\n",
    "        all_model_responses.append(reasoning_samples)\n",
    "        individual_predictions_list.append(predictions)\n",
    "        final_predictions.append(final_prediction)\n",
    "        \n",
    "        sleep(1)  \n",
    "    \n",
    "    result_df = pd.DataFrame({\n",
    "        'text_id': text_ids, \n",
    "        'text': text_list, \n",
    "        'all_reasoning_samples': all_model_responses,  \n",
    "        'individual_predictions': individual_predictions_list,\n",
    "        'corrected_model_responses': final_predictions, \n",
    "        'true_label': answers\n",
    "    })\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf17cdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt for Self Consistency\n",
    "def create_self_consistency_prompt():\n",
    "\n",
    "    categories = get_all_categories()\n",
    "    categories_text = \", \".join(categories)\n",
    "    \n",
    "    prompt_prefix_sc = f\"\"\"\n",
    "Classify the following Combined Arabic and English text into one of these categories:\n",
    "{categories_text}.\n",
    "\n",
    "Analyze the text and decide the most suitable category.\n",
    "\n",
    "Output format: Only write the final category name with no explanation, no extra text, and no punctuation.\n",
    "\"\"\"\n",
    "\n",
    "    \n",
    "    examples_sc = '''\n",
    "Example 1:\n",
    "Input Text: تطوير business strategy فعاله يعتمد علي فهم market trends بشكل شامل\n",
    "Reasoning: This text discusses business strategy development and market trends analysis, which are core business concepts. The keywords \"business strategy\" and \"market trends\" clearly indicate this belongs to business category.\n",
    "Final Answer: business\n",
    "\n",
    "Example 2:\n",
    "Input Text: اذا كنت ترغب في تحسين mental health يجب عليك ممارسه mindfulness بانتظام\n",
    "Reasoning: The text focuses on mental health improvement through mindfulness practice. Keywords like \"mental health\" and \"mindfulness\" are health-related topics about psychological well-being.\n",
    "Final Answer: health\n",
    "\n",
    "Example 3:\n",
    "Input Text: استخدام machine learning في data analysis يحسن دقة التنبؤات\n",
    "Reasoning: This text discusses machine learning and data analysis for improving prediction accuracy. These are technical concepts related to technology and artificial intelligence.\n",
    "Final Answer: tech\n",
    "'''\n",
    "    \n",
    "    prompt_suffix_sc = \"Reasoning: \"\n",
    "    \n",
    "    return prompt_prefix_sc, examples_sc, prompt_suffix_sc\n",
    "\n",
    "prompt_config_sc = {\n",
    "    'max_tokens': 150, \n",
    "    'temperature': 0.7,  \n",
    "    'top_p': 0.9,\n",
    "    'stop': ['\\nInput Text:', 'Example:']  # Stop conditions\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05d9ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test The Model \n",
    "prompt_prefix_sc, prompt_examples_sc, prompt_suffix_sc = create_self_consistency_prompt()\n",
    "results_df = self_consistency_prompting(\n",
    "    data, \n",
    "    prompt_config_sc, \n",
    "    prompt_examples_sc, \n",
    "    prompt_prefix_sc, \n",
    "    prompt_suffix_sc,\n",
    "    pre_processing=your_pre_processing_zs,\n",
    "    post_processing=self_consistency_post_processing,\n",
    "    model=model,\n",
    "    num_samples=3, \n",
    "    debug=False\n",
    ")\n",
    "\n",
    "print(results_df[['text_id', 'text', 'corrected_model_responses', 'true_label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6d6673",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(results_df['true_label'], results_df['corrected_model_responses'],average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1b0680",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(results_df['true_label'], results_df['corrected_model_responses']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247f5990",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cbd976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config The Model as a Client waiting for prompt\n",
    "client = Groq(api_key=\"\")\n",
    "def chat_completion(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama-3.3-70b-versatile\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7499a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load The data\n",
    "df = pd.read_excel(\"train_split.xlsx\")\n",
    "df[\"combined\"] = df.astype(str).agg(\" \".join, axis=1)\n",
    "texts = df[\"text\"].astype(str).tolist()\n",
    "labels = df[\"label\"].astype(str).tolist()\n",
    "print(f\"Loaded {len(df)} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e6acae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform The Date from Sentence to vector to can Handle it \n",
    "\n",
    "# model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "# embeddings = model.encode(texts, convert_to_numpy=True).astype(\"float32\")\n",
    "\n",
    "# dimension = embeddings.shape[1]\n",
    "# index = faiss.IndexFlatL2(dimension)\n",
    "# index.add(embeddings)\n",
    "# print(f\"FAISS index built with {index.ntotal} vectors.\")\n",
    "# faiss.write_index(index, \"faiss_index.bin\")\n",
    "# print(\"FAISS index saved to faiss_index.bin\")\n",
    "\n",
    "# if we Have the Index File\n",
    "index = faiss.read_index(\"faiss_index.bin\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c42de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare The Function to Test The Data with The Prompt For 3 times\n",
    "def classify_text(query, k=3):\n",
    "    query_emb = model.encode([query], convert_to_numpy=True).astype(\"float32\")\n",
    "    distances, indices = index.search(query_emb, k)\n",
    "\n",
    "    top_examples = [texts[i] for i in indices[0]]\n",
    "    top_labels = [labels[i] for i in indices[0]]\n",
    "\n",
    "    context = \"\\n\".join([\n",
    "        f\"Example {i+1}:\\nText: {top_examples[i]}\\nLabel: {top_labels[i]}\"\n",
    "        for i in range(len(top_examples))\n",
    "    ])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a text classification assistant. \n",
    "Based on the following labeled examples, determine the most likely label for the new text.\n",
    "\n",
    "Labeled examples:\n",
    "{context}\n",
    "\n",
    "Now classify this new text:\n",
    "\"{query}\"\n",
    "\n",
    "Respond only with the most appropriate label.\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama-3.3-70b-versatile\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    model_label = response.choices[0].message.content.strip()\n",
    "\n",
    "    return model_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2a1148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test The RAG on the Number from Data\n",
    "df = pd.read_excel(\"test_split.xlsx\")\n",
    "sample_df = df.sample(n=50, random_state=42).reset_index(drop=True)\n",
    "texts_test = sample_df[\"text\"].astype(str).tolist()\n",
    "true_labels = sample_df[\"label\"].astype(str).tolist()\n",
    "predicted_labels = []\n",
    "for i, query_text in enumerate(texts_test):\n",
    "    predicted = classify_text(query_text)\n",
    "    predicted_labels.append(predicted)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(f\"The Accuracy is :{accuracy:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
